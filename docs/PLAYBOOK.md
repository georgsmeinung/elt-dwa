# ðŸ“˜ PLAYBOOK: AutomatizaciÃ³n de Data Warehouse con SQLMesh

Este playbook guÃ­a paso a paso cÃ³mo implementar una arquitectura de **Data Warehouse Automation (DWA)** utilizando Ãºnicamente **SQLMesh**. Todo el flujo es 100% open source.

---

## ðŸ”§ Requisitos Previos

- Docker y Docker Compose instalados
- Acceso a una terminal (Linux, macOS, Windows WSL)
- Clonar este repositorio:

```bash
git clone <url-del-repo>
cd elt-dwa-sqlmesh
```

---

## ðŸš€ Paso 1: Levantar el entorno

```bash
docker compose up -d
```

Esto levanta los siguientes servicios:
- PostgreSQL â†’ base de datos del DWH
- SQLMesh UI â†’ entorno visual de modelado y ejecuciÃ³n
- Apache NiFi â†’ para ingestiÃ³n visual de archivos CSV
- Lightdash â†’ dashboards sobre los modelos `dp_`
- DBGate â†’ para consultar y validar los datos manualmente

---

## ðŸ—‚ Paso 2: Cargar archivos de datos

1. AccedÃ© a NiFi en `http://localhost:8080`
2. DiseÃ±Ã¡ un flujo para cargar los CSV desde `./data/ingesta1/` hacia PostgreSQL
3. Las tablas deben llamarse con prefijo `tmp_` (por ejemplo, `tmp_orders`, `tmp_customers`)

> Alternativamente, podÃ©s usar DBGate para cargar datos manualmente.

---

## ðŸ§  Paso 3: Comprender las capas del modelo

```plaintext
[CSV] â†’ NiFi â†’ TMP_ (staging) â†’ SQLMesh â†’ DWA_ / DWM_ / DQM_ / DP_ â†’ Lightdash
```

- `tmp_`: staging directo desde los CSV
- `dwa_`: transformaciones limpias y normalizadas
- `dwm_`: modelos histÃ³ricos (SCD Tipo 2)
- `dqm_`: control de calidad (nulos, duplicados, trazabilidad)
- `dp_`: vistas finales para dashboards y BI

---

## âœï¸ Paso 4: Editar modelos SQL

Los modelos estÃ¡n en `./models/` organizados por capa. Cada archivo `.sql` contiene:

1. Un bloque `MODEL(...)` de configuraciÃ³n
2. Una query SQL estÃ¡ndar

Ejemplo:
```sql
MODEL (
  name d_wa_orders,
  kind FULL,
  cron '@daily'
);

SELECT * FROM model('tmp_orders') WHERE orderdate IS NOT NULL;
```

- `model('tmp_orders')` define la dependencia entre modelos
- Cada archivo es autocontenido y versionable

---

## âš™ï¸ Paso 5: Compilar y aplicar los modelos

Desde la terminal:

```bash
docker exec -it elt_sqlmesh bash
cd /app/sqlmesh
sqlmesh plan
sqlmesh apply
```

- `plan` verifica quÃ© modelos cambiaron y simula el impacto
- `apply` ejecuta las transformaciones en orden correcto

> TambiÃ©n podÃ©s hacerlo desde la UI: `http://localhost:8084`

---

## ðŸ§ª Paso 6: Ver y validar los resultados

### DBGate
- URL: `http://localhost:8082`
- Usuario: `elt_user`, ContraseÃ±a: `elt_pass`
- ConsultÃ¡ las tablas `dwa_`, `dwm_`, `dqm_`, `dp_`

### Lightdash
- URL: `http://localhost:8081`
- Explora dashboards directamente desde las vistas `dp_*`

---

## ðŸ§© Estructura del proyecto

```bash
elt-dwa/
â”œâ”€â”€ models/                      # Modelos SQL por capa
â”‚   â”œâ”€â”€ tmp/                     # Staging
â”‚   â”œâ”€â”€ dwa/                     # Transformaciones limpias
â”‚   â”œâ”€â”€ dwm/                     # HistÃ³ricos con SCD2
â”‚   â”œâ”€â”€ dqm/                     # Calidad de datos
â”‚   â””â”€â”€ dp/                      # Producto de datos
â”œâ”€â”€ docs/                      # Documentacion detallada
â”œâ”€â”€ sqlmesh_project.toml        # ConfiguraciÃ³n del proyecto
â”œâ”€â”€ docker-compose.yml          # Servicios y puertos
â”œâ”€â”€ data/ingesta1/              # Archivos CSV
â””â”€â”€ README.md                   # DocumentaciÃ³n principal

```

---

## ðŸ§  Tips adicionales

- SQLMesh puede trabajar con mÃºltiples entornos (`dev`, `prod`) y comparar resultados
- Las transformaciones son **SQL + YAML**, sin necesidad de Python
- PodÃ©s agregar tests custom con Python si lo necesitÃ¡s
